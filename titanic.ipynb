{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Titanic Survivors Logistic Regression\n",
    "\n",
    "**Matthew Rogers**\n",
    "**7/5/2021**\n",
    "\n",
    "The sinking of the Titanic in 1912 remains one of the most deadly and infamous maritime disasters in history. of the 2224 passengers, 1502 were killed after the ship struck an iceberg in the atlantic ocean. Using a dataset from kaggle found [here](https://www.kaggle.com/c/titanic/overview), we can create a logistic regression model to predict whether different passengers lived or died in the disaster. \n",
    "\n",
    "### Basic Data Exploration\n",
    "\n",
    "The data comes already split into a training and testing set. Since we don't want to even look at the testing set, we can load only the training set first and start looking at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 12 variables are described as such\n",
    "\n",
    "|Var. Name |Description |Key |\n",
    "| --- | --- | --- |\n",
    "| Survival | passenger survived y/n | 0 = no, 1 = yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | passenger sex | |\n",
    "| age | age in years | |\n",
    "| sibsp | number of siblings/spouses aboard | |\n",
    "| parch | number of parents/children aboard | |\n",
    "| ticket | ticket number | |\n",
    "| fare | how much was paid for the ticket | |\n",
    "| cabin | cabin number | |\n",
    "| embarked | where the passenger embarked | C = Cherbourg, Q = Queenstown, S = Southhampton |\n",
    "\n",
    "Now lets look for any NA values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, Cabin, and Embarked are the only variables with missing values. Cabin might have too many missing values to work with it in our model, but we can look at age to see if imputing or removing the values could be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% missing in Age:  0.199\n",
      "% missing in Cabin:  0.771\n",
      "% missing in Embarked:  0.002\n"
     ]
    }
   ],
   "source": [
    "print(\"% missing in Age: \", round(train[\"Age\"].isna().sum()/train.shape[0], 3))\n",
    "print(\"% missing in Cabin: \", round(train[\"Cabin\"].isna().sum()/train.shape[0], 3))\n",
    "print(\"% missing in Embarked: \", round(train[\"Embarked\"].isna().sum()/train.shape[0], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, 77% of the Cabin is missing, we should probably drop it. We might be able to work with Age, and since so little of Embarked is missing, we should be able to just drop the two offending rows. Lets take a look at the distribution of age to see where we should go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(train[\"Age\"], bins = 15, color = \"dodgerblue\", edgecolor = \"white\")\n",
    "plt.title(\"Histogram of Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.axvline(train[\"Age\"].mean(), linestyle = \"dashed\", color = \"g\")\n",
    "plt.text(train[\"Age\"].mean()*1.1, plt.ylim()[1] * 0.9, \"Mean: {:.2f}\".format(train[\"Age\"].mean()))\n",
    "\n",
    "plt.axvline(train[\"Age\"].median(), linestyle = \"dashed\", color = \"k\")\n",
    "plt.text(train[\"Age\"].median()*0.25, plt.ylim()[1] * 0.9, \"Median: {:.2f}\".format(train[\"Age\"].median()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is only slightly lower than the mean, but since the data has some spikiness towards the left I'm leaning towards using the median to impute the 177 missing values in the age column. \n",
    "\n",
    "Since only 2 values are missing in the Embarked column, I believe it's safe to simply drop them. \n",
    "\n",
    "So to make the final transformations, we're going to:\n",
    "\n",
    " - Drop the \"Cabin\" column\n",
    " - Impute the median for missing \"Age\" values\n",
    " - Drop the 2 rows with missing \"Embarked\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polish = train.copy()\n",
    "\n",
    "train_polish.drop(\"Cabin\", axis = 1, inplace = True)\n",
    "train_polish = train_polish.dropna(subset = [\"Embarked\"])\n",
    "train_polish[\"Age\"].fillna(train[\"Age\"].median(skipna = True), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polish.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the data cleaned up! One final thing we can do is change the \"embarked\" and \"sex\" columns to dummy variables (one hot encoding) to make the regression easier (or to just use them at all in a regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polish = pd.get_dummies(train_polish, columns = [\"Sex\", \"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>-0.035330</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>-0.043136</td>\n",
       "      <td>0.043136</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.033694</td>\n",
       "      <td>0.022269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335549</td>\n",
       "      <td>-0.069822</td>\n",
       "      <td>-0.034040</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.255290</td>\n",
       "      <td>0.541585</td>\n",
       "      <td>-0.541585</td>\n",
       "      <td>0.169966</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>-0.151777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035330</td>\n",
       "      <td>-0.335549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.336512</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>-0.548193</td>\n",
       "      <td>-0.127741</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>-0.245733</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>0.076466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.031319</td>\n",
       "      <td>-0.069822</td>\n",
       "      <td>-0.336512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.232543</td>\n",
       "      <td>-0.171485</td>\n",
       "      <td>0.093707</td>\n",
       "      <td>-0.086506</td>\n",
       "      <td>0.086506</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-0.008964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.034040</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>-0.232543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414542</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>-0.116348</td>\n",
       "      <td>-0.060074</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>0.069438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001657</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>-0.171485</td>\n",
       "      <td>0.414542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217532</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>-0.247508</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>0.061512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.255290</td>\n",
       "      <td>-0.548193</td>\n",
       "      <td>0.093707</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>0.217532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179958</td>\n",
       "      <td>-0.179958</td>\n",
       "      <td>0.270731</td>\n",
       "      <td>-0.116684</td>\n",
       "      <td>-0.163758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>-0.043136</td>\n",
       "      <td>0.541585</td>\n",
       "      <td>-0.127741</td>\n",
       "      <td>-0.086506</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.179958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.084520</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>-0.121405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>0.043136</td>\n",
       "      <td>-0.541585</td>\n",
       "      <td>0.127741</td>\n",
       "      <td>0.086506</td>\n",
       "      <td>-0.116348</td>\n",
       "      <td>-0.247508</td>\n",
       "      <td>-0.179958</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084520</td>\n",
       "      <td>-0.075217</td>\n",
       "      <td>0.121405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001208</td>\n",
       "      <td>0.169966</td>\n",
       "      <td>-0.245733</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>-0.060074</td>\n",
       "      <td>-0.011588</td>\n",
       "      <td>0.270731</td>\n",
       "      <td>0.084520</td>\n",
       "      <td>-0.084520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>-0.782613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033694</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>0.220558</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-0.026692</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>-0.116684</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>-0.075217</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022269</td>\n",
       "      <td>-0.151777</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>-0.008964</td>\n",
       "      <td>0.069438</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>-0.163758</td>\n",
       "      <td>-0.121405</td>\n",
       "      <td>0.121405</td>\n",
       "      <td>-0.782613</td>\n",
       "      <td>-0.499261</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005028 -0.035330  0.031319 -0.057686 -0.001657   \n",
       "Survived       -0.005028  1.000000 -0.335549 -0.069822 -0.034040  0.083151   \n",
       "Pclass         -0.035330 -0.335549  1.000000 -0.336512  0.081656  0.016824   \n",
       "Age             0.031319 -0.069822 -0.336512  1.000000 -0.232543 -0.171485   \n",
       "SibSp          -0.057686 -0.034040  0.081656 -0.232543  1.000000  0.414542   \n",
       "Parch          -0.001657  0.083151  0.016824 -0.171485  0.414542  1.000000   \n",
       "Fare            0.012703  0.255290 -0.548193  0.093707  0.160887  0.217532   \n",
       "Sex_female     -0.043136  0.541585 -0.127741 -0.086506  0.116348  0.247508   \n",
       "Sex_male        0.043136 -0.541585  0.127741  0.086506 -0.116348 -0.247508   \n",
       "Embarked_C     -0.001208  0.169966 -0.245733  0.032098 -0.060074 -0.011588   \n",
       "Embarked_Q     -0.033694  0.004536  0.220558 -0.030436 -0.026692 -0.081585   \n",
       "Embarked_S      0.022269 -0.151777  0.076466 -0.008964  0.069438  0.061512   \n",
       "\n",
       "                 Fare  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "PassengerId  0.012703   -0.043136  0.043136   -0.001208   -0.033694   \n",
       "Survived     0.255290    0.541585 -0.541585    0.169966    0.004536   \n",
       "Pclass      -0.548193   -0.127741  0.127741   -0.245733    0.220558   \n",
       "Age          0.093707   -0.086506  0.086506    0.032098   -0.030436   \n",
       "SibSp        0.160887    0.116348 -0.116348   -0.060074   -0.026692   \n",
       "Parch        0.217532    0.247508 -0.247508   -0.011588   -0.081585   \n",
       "Fare         1.000000    0.179958 -0.179958    0.270731   -0.116684   \n",
       "Sex_female   0.179958    1.000000 -1.000000    0.084520    0.075217   \n",
       "Sex_male    -0.179958   -1.000000  1.000000   -0.084520   -0.075217   \n",
       "Embarked_C   0.270731    0.084520 -0.084520    1.000000   -0.148646   \n",
       "Embarked_Q  -0.116684    0.075217 -0.075217   -0.148646    1.000000   \n",
       "Embarked_S  -0.163758   -0.121405  0.121405   -0.782613   -0.499261   \n",
       "\n",
       "             Embarked_S  \n",
       "PassengerId    0.022269  \n",
       "Survived      -0.151777  \n",
       "Pclass         0.076466  \n",
       "Age           -0.008964  \n",
       "SibSp          0.069438  \n",
       "Parch          0.061512  \n",
       "Fare          -0.163758  \n",
       "Sex_female    -0.121405  \n",
       "Sex_male       0.121405  \n",
       "Embarked_C    -0.782613  \n",
       "Embarked_Q    -0.499261  \n",
       "Embarked_S     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polish.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can combine the SibSp and Parch into one column of just \"relatives on board\". I'll make a categorical and numeric variable to see if one is a stronger predictor than the other.  Let's do that and see if it adds a meaningful variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_polish[\"relatives_cat\"] = np.where(((train_polish[\"SibSp\"] > 0) & (train_polish[\"SibSp\"] > 0)), 1, 0)\n",
    "train_polish[\"relatives_num\"] = train_polish[\"SibSp\"] + train_polish[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     -0.005028\n",
       "Survived         1.000000\n",
       "Pclass          -0.335549\n",
       "Age             -0.069822\n",
       "SibSp           -0.034040\n",
       "Parch            0.083151\n",
       "Fare             0.255290\n",
       "Sex_female       0.541585\n",
       "Sex_male        -0.541585\n",
       "Embarked_C       0.169966\n",
       "Embarked_Q       0.004536\n",
       "Embarked_S      -0.151777\n",
       "relatives_cat    0.118087\n",
       "relatives_num    0.018277\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polish.corr()[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relatives categorical predictor does a much better job predicting a passengers outcome than the numeric value, so I'll keep that and drop the other two variables representing the number of relatives on board.\n",
    "\n",
    "In addition I'll be dropping the Name, Ticket number, and PassengerId variables as previously mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Parch\", \"SibSp\", \"Name\", \"PassengerId\", \"Ticket\", \"relatives_num\"]\n",
    "train_polish = train_polish.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         1.000000\n",
       "Pclass          -0.335549\n",
       "Age             -0.069822\n",
       "Fare             0.255290\n",
       "Sex_female       0.541585\n",
       "Sex_male        -0.541585\n",
       "Embarked_C       0.169966\n",
       "Embarked_Q       0.004536\n",
       "Embarked_S      -0.151777\n",
       "relatives_cat    0.118087\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_polish.corr()[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good! We can scale our dataset to give the model a little bit of an easier time working. However we should split the data into our training/testing sets first, as both sets should more or less represent fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# drop the survived column \n",
    "survived = train_polish[\"Survived\"]\n",
    "preds = train_polish.drop(\"Survived\", axis = 1)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(preds, survived, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data scaled, we're ready to train the initial model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression()\n",
    "mod.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how the model did by running it against the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752808988764045"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model has a mean accuracy score of around 77%, which is a pretty solid first attempt! I'm only trying to do a basic regression here, but further options would include removing the age category, as it has a low correlation with survived, or creating some new factors to evaluate like a status variable created from the name variable. \n",
    "\n",
    "Before wrapping up we should create our predictions from the testing data given by the kaggle source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "passengerids = test[\"PassengerId\"]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"relatives_cat\"] = np.where(((test[\"SibSp\"] > 0) & (test[\"SibSp\"] > 0)), 1, 0)\n",
    "test = pd.get_dummies(test, columns = [\"Sex\", \"Embarked\"])\n",
    "cols = [\"Parch\", \"SibSp\", \"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"]\n",
    "test = test.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Age\"].fillna(test[\"Age\"].median(skipna = True), inplace = True)\n",
    "test[\"Fare\"].fillna(test[\"Fare\"].median(skipna = True), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mod.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passenger Ids</th>\n",
       "      <th>survived (predicted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Passenger Ids  survived (predicted)\n",
       "0              892                     0\n",
       "1              893                     0\n",
       "2              894                     0\n",
       "3              895                     0\n",
       "4              896                     0\n",
       "..             ...                   ...\n",
       "413           1305                     0\n",
       "414           1306                     0\n",
       "415           1307                     0\n",
       "416           1308                     0\n",
       "417           1309                     1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = {\"Passenger Ids\": passengerids, \"survived (predicted)\": predictions}\n",
    "final_preds = pd.DataFrame(dat, columns = [\"Passenger Ids\", \"survived (predicted)\"])\n",
    "final_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
